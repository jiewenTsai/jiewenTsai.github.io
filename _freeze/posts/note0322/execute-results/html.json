{
  "hash": "5014856a99c6a65bde150b8c8d6b88b7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"How to conduct simple slope analysis and make plot with `brms`\"\nauthor: 'JW Tsai'\ndate: 2024-03-22\ncategories: \n  - brms\n  - Bayesian\n---\n\n\n**Goal.** In this note, we will demonstrate how to use the output from `brms` to make (simple slope) testings and plots.\n\n## Make data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(bayestestR)\nlibrary(rstan)\nlibrary(mvtnorm)\n```\n:::\n\n\nNow we have to make a data set including 4 variables: Y, X, M, and W.\n\nSuppose these four variables follow a multivariate-normal distribution as follows,\n\nLet X is a treatment (binary data), and M is a response time data (lognormal).\n\n\n```{=tex}\n\\begin{equation}\n\\begin{bmatrix}\nY \\\\ X \\\\M \\\\W \n\\end{bmatrix}\n= \\text{MVN}\\left(\n\\begin{bmatrix}\n0 \\\\0 \\\\ 0\\\\ 0\n\\end{bmatrix},\n\\begin{bmatrix}\n1 & 0.1 & -0.8 & 0.8  \\\\\n0.1 & 1 & -0.6 & 0\\\\ \n-0.8 & -0.6 & 1 & 0.6\\\\\n0.8 & 0 & 0.6 & 1\n\\end{bmatrix}\n\\right)\n\\end{equation}\n```\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\nreal_sigma <- matrix(c(1, 0.1, -0.8, 0.8,\n                      0.1, 1, -0.6, 0,\n                      -0.8, -0.6, 1, 0.6,\n                      0.8, 0, 0.6, 1), nrow = 4)\nreal_mean <- c(0,0,0,0)\n\nreal_data <- rmvnorm(n = 1000, mean = real_mean, sigma = real_sigma)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in rmvnorm(n = 1000, mean = real_mean, sigma = real_sigma): sigma is\nnumerically not positive semidefinite\n```\n\n\n:::\n\n```{.r .cell-code}\ndat <- data.frame(\n  ID = paste0('s', str_pad(1:1000, width = 4, side = 'left', pad = 0)),\n  Y = real_data[,1],\n  X = real_data[,2] > mean(real_data[,2]),\n  M = exp(real_data[,3]),\n  W = real_data[,4]\n)\n\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     ID          Y     X         M          W\n1 s0001  0.3617174  TRUE 0.4790760 -0.1639895\n2 s0002  0.1110080 FALSE 2.0490296  0.2046531\n3 s0003  0.6187169 FALSE 2.6247616  1.4401394\n4 s0004  1.0347476  TRUE 0.5084054  0.6434533\n5 s0005 -1.1477318 FALSE 4.8633851  0.2686688\n6 s0006  0.2802449  TRUE 0.1476185 -1.2412565\n```\n\n\n:::\n:::\n\n\n## Fit Bayesian model in `brms`\n\nNow we specify the formula as follows (in Bayesian).\n\n\n```{=tex}\n\\begin{align}\n\\text{Likelihood.}\\\\\nY &\\sim N(\\mu_y, \\sigma_y^2) \\\\\nM &\\sim \\log N(\\mu_m, \\sigma_m^2) \\\\\n\n\\mu_y &= \\beta_{01} + \\beta_x X + \\beta_m M + \\beta_w W + \\beta _{mw}M \\cdot W \\\\\n\\mu_m &= \\beta_{02} + \\beta_x X \\\\ \\\\\n\n\\text{Priors.}\\\\\n\n\\sigma_y^2, \\sigma_m^2 & \\sim \\text{Exp}(1) \\\\\n\\beta_{01}, ..., \\beta _{x} &\\sim N(0,5) \n\\end{align}\n```\n\n::: {.cell}\n\n```{.r .cell-code}\nbf1 <- bf(Y~X+M+W+M*W, family = gaussian())\nbf2 <- bf(M~X, family = lognormal())\npriors <- prior(normal(0,5), class = b, resp = Y) + \n  prior(normal(0,5), class = b, resp = M) + \n  prior(exponential(1), class = sigma, resp = Y) +\n  prior(exponential(1), class = sigma, resp = M) \n\n\n\nfit <- brm(\n  bf1+bf2+set_rescor(FALSE), \n  data = dat,\n  cores = 4\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(fit, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: MV(gaussian, lognormal) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: Y ~ X + M + W + M * W \n         M ~ X \n   Data: dat (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nY_Intercept    0.648     0.035    0.580    0.716 1.001     4338     3242\nM_Intercept    0.490     0.043    0.407    0.574 1.002     4917     3090\nY_XTRUE       -0.164     0.039   -0.241   -0.086 1.000     4874     3349\nY_M           -0.366     0.010   -0.386   -0.346 1.001     3476     3265\nY_W            0.604     0.020    0.565    0.641 1.000     4427     3384\nY_M:W          0.100     0.006    0.088    0.112 1.000     2928     2864\nM_XTRUE       -0.856     0.059   -0.970   -0.742 1.001     5208     2953\n\nFurther Distributional Parameters:\n        Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nsigma_Y    0.570     0.013    0.544    0.597 1.000     5277     2537\nsigma_M    0.962     0.021    0.921    1.005 1.002     5424     2974\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Bayesian testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> \n  describe_posterior(\n    effects = \"all\",\n    component = \"all\",\n    #test = c(\"p_direction\", \"p_significance\"),\n    centrality = \"all\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Multivariate response models are not yet supported for tests `rope` and\n  `p_rope`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSummary of Posterior Distribution M\n\nParameter   | Response | Median |  Mean |   MAP |         95% CI |   pd |  Rhat |     ESS\n-----------------------------------------------------------------------------------------\n(Intercept) |        M |   0.49 |  0.49 |  0.49 | [ 0.41,  0.57] | 100% | 1.000 | 4898.00\nXTRUE       |        M |  -0.85 | -0.86 | -0.85 | [-0.97, -0.74] | 100% | 0.999 | 5258.00\n\n# Fixed effects sigma M\n\nParameter | Response | Median | Mean |  MAP |         95% CI |   pd |  Rhat |     ESS\n-------------------------------------------------------------------------------------\nsigma     |        M |   0.96 | 0.96 | 0.96 | [ 0.92,  1.00] | 100% | 1.000 | 5345.00\n\n# Fixed effects Y\n\nParameter   | Response | Median |  Mean |   MAP |         95% CI |   pd |  Rhat |     ESS\n-----------------------------------------------------------------------------------------\n(Intercept) |        Y |   0.65 |  0.65 |  0.65 | [ 0.58,  0.72] | 100% | 1.000 | 4325.00\nXTRUE       |        Y |  -0.16 | -0.16 | -0.16 | [-0.24, -0.09] | 100% | 1.000 | 4867.00\nM           |        Y |  -0.37 | -0.37 | -0.36 | [-0.39, -0.35] | 100% | 1.001 | 3499.00\nW           |        Y |   0.60 |  0.60 |  0.60 | [ 0.56,  0.64] | 100% | 1.000 | 4384.00\nM:W         |        Y |   0.10 |  0.10 |  0.10 | [ 0.09,  0.11] | 100% | 1.000 | 2908.00\n\n# Fixed effects sigma Y\n\nParameter | Response | Median | Mean |  MAP |         95% CI |   pd |  Rhat |     ESS\n-------------------------------------------------------------------------------------\nsigma     |        Y |   0.57 | 0.57 | 0.57 | [ 0.54,  0.60] | 100% | 1.000 | 5226.00\n```\n\n\n:::\n:::\n\n\nThe function `hypothesis()` can be used to test specific parameter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_hypo <- hypothesis(\n  fit, \n  class = 'b',\n  alpha = .05,\n  hypothesis = \n  c(\n    Low = \"Y_M - Y_M:W = 0\",\n    Medium = \"Y_M = 0\",\n    High = \"Y_M + Y_M:W = 0\")\n  ) \nfit_hypo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nHypothesis Tests for class b:\n  Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1        Low    -0.47      0.02    -0.50    -0.44         NA        NA    *\n2     Medium    -0.37      0.01    -0.39    -0.35         NA        NA    *\n3       High    -0.27      0.01    -0.28    -0.25         NA        NA    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n\n\n:::\n:::\n\n\n## Make plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## plotting ----\ncond_plot <- conditional_effects(fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncond_plot$`Y.Y_M:W` |>\n  ggplot(aes(x = M, y = Y), ) +\n  \n  geom_ribbon(aes(x = effect1__, y = estimate__, linetype = effect2__,\n                  ymin = lower__, ymax = upper__, fill = factor(effect2__)), alpha = 0.5) +\n  geom_line(aes(x = effect1__, y = estimate__, linetype = effect2__)) +\n  scale_fill_manual(name = 'W effects',\n                    values = c(\"coral4\", \"coral3\", \"coral2\"),\n                    labels = c(\"High \\n(Mean+1SD)\", \"Average \\n(Mean)\", \"Low \\n(Mean-1SD)\"),\n                    ) +\n  scale_linetype_manual(name = 'W effects',\n                        values = c(\"solid\", \"dotted\", \"dashed\"),\n                        labels = c(\"High \\n(Mean+1SD)\", \"Average \\n(Mean)\", \"Low \\n(Mean-1SD)\")) +\n  labs(x = \"the M\", \n       y = \"the Y\") +\n  ggtitle('M * W') +\n  annotate(\"text\", x=10, y=-8, label= \"Low \\n b=-0.47, [-0.49, -0.44]\") +\n  annotate(\"text\", x=25, y=-7, label= \"Average \\n b=-0.37, [-0.38, -0.35]\") +\n  annotate(\"text\", x=20, y=0, label= \"High \\n b=-0.27, [-0.28, -0.25]\") +\n  \n  theme_minimal(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](note0322_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "note0322_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}